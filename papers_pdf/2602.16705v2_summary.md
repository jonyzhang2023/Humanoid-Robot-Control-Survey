# Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation

**Authors:** Runpei Dong, Ziyan Li, Xialin He, Saurabh Gupta
**Link:** http://arxiv.org/abs/2602.16705v2

## Abstract (from PDF parsing)
...

## Method / Approach (Snippets)
Translation Rotation Error (cm) Error (deg) a) End-effector Pose Analytical FK 1.76 5.87 Learned FK (ours) 0.27 2.30 Learned FK, no residual (ours) 0.35 2.98 b) Base Odometry Analytical FK 1.10 0.49 Learned FK (ours) 0.33 0.36 Learned FK, no residual (ours) 0.37 0.42 model reduces the error by 6× indicates that analytical forward kinematics model errors are systematic. Tab. II also reports an ablation where we directly try to predict the end-effector pose without using the estimate from analytical FK and note that it does worse. Base Odometry. Tab. II also reports base odometry results. Once again, we see that the residual neural model is better than both analytical FK and a non-residual neural model. Execution Curves. We compare analytical and neural forward- model errors over time in Fig. 7. While analytical FK exhibits a persistent bias above 1.75 cm during reaching, our neural model η remains below 0.25 cm throughout. Similarly, as whole-body balancing causes analytical odometry drift to grow, our neural odometry model ξ reduces this drift by about 3× relative to the analytical baseline. D. End-effector Tracking Accuracy Evaluation We evaluate the performance of different tracking methods in simulation and in the real world under MOCAP. We evaluate different tracking methods on a fixed set of 180 reaching goals. The goal distribution is designed to reflect realistic grasping scenarios: we sample from three different table heights, with z-coordinates ranging from 5-15cm ab...

## Conclusion (Snippets)
...
