---
outline: deep
---

# 技术路线对比分析

### 15.1 两大范式：基于模型 vs 基于学习

| 维度 | 基于模型（MPC / WBC） | 基于学习（RL / IL） |
|------|--------------------|--------------------|
| **代表** | Atlas WBC, IHMC Controller, LIPM-MPC | ExBody2, HumanPlus, DWL |
| **核心方法** | 在线优化 / 逆动力学 / QP 求解 | 大规模并行仿真中训练策略 |
| **环境建模** | 需要精确的机器人动力学模型 | 从数据中自动学习 |
| **训练需求** | 无需额外训练 | 需要大量仿真训练 |
| **推理成本** | 高（在线优化 ~ms 级） | 低（策略前向传播 ~μs 级） |
| **运动自然性** | 低（机械感强） | 高（可从人体运动学习） |
| **安全保障** | ✅ 可显式约束 | ❌ 黑箱策略 |
| **泛化能力** | 低（需针对每种情况建模） | 高（域随机化增强） |
| **当前趋势** | 与 RL 融合（RL+MPC 混合） | 主流方向，加速走向基础模型 |

### 15.2 架构演进路线

```
[2000-2015] ZMP + PD 控制 (ASIMO)
  ↓
[2016-2018] 全身控制 WBC + QP 优化 (Atlas DRC)
  ↓
[2018-2020] 参考运动模仿 RL (DeepMimic)
  ↓
[2021-2023] 对抗运动先验 + Sim-to-Real (AMP, DWL)
  ↓
[2024-2025] 大规模 MoCap 预训练 + 教师-学生蒸馏 (ExBody2, HumanPlus)
  ↓
[2025-2026] 行为基础模型 + 多模态控制接口 (SONIC, GR00T N1)
  ↓
[2026+?] 统一世界模型+控制：感知-规划-控制一体化
```

### 15.3 五大研究方向核心维度对比

| 维度 | 全身控制 | HSI | HOI | 感知移动 | 感知导航 |
|------|---------|-----|-----|---------|---------|
| 运动自然性 | ✅ 核心 | ✅ 关键 | 🟡 | 🟡 | ❌ 非重点 |
| 地形适应 | 🟡 | ❌ | ❌ | ✅ 核心 | ✅ 关键 |
| 物体操控 | ❌ | 🟡 | ✅ 核心 | ❌ | ❌ |
| 场景理解 | ❌ | ✅ 核心 | 🟡 | 🟡 | ✅ 核心 |
| 真机验证 | ✅ 成熟 | 🟡 起步 | 🟡 | ✅ 成熟 | ❌ 早期 |
| 数据来源 | MoCap | 场景扫描 | 遥操作 | 仿真 | 仿真+真实 |

### 15.4 训练策略对比

| 策略 | 适用方向 | 核心思想 | 代表工作 |
|------|---------|---------|---------|
| **大规模 MoCap 预训练** | 全身控制 | 从数千小时 MoCap 数据学习运动基元 | SONIC, ExBody2 |
| **教师-学生蒸馏** | 感知移动 | 教师用特权信息训练，学生仅用真实传感器 | HPC, DWL |
| **AMP / 对抗训练** | 全身控制, HSI | GAN 判别器学习运动风格 | AMP, UniHSI |
| **视觉域随机化** | HOI | 随机化视觉因素增强视觉策略 | VIRAL |
| **VR 遥操作+模仿** | HOI | 人类遥操作采集，模仿学习训练 | TRILL, H2O |
| **课程/渐进训练** | 感知移动 | 逐步增加任务难度 | 大多数运动训练 |

### 15.5 计算成本量化对比

| 方法 | 参数量 | 训练资源 | 推理延迟 | 部署平台 |
|------|--------|---------|---------|---------|
| ExBody2 | ~10M | 数块 GPU · 数天 | ~1ms/step | Unitree G1/H1 |
| HumanPlus | ~50M | 8 GPU · 数天 | ~5ms/step | 自定义 33DoF |
| SONIC | ~100M+ | 大规模 GPU 集群 | ~2ms/step | 多平台 |
| GR00T N1 | 数十亿 | 大规模集群 | ~50ms/step | 通用 |
| HPC | ~10M | 数块 GPU · 数天 | ~1ms/step | 真实人形 |
| DWL | ~5M | 单机数天 | ~1ms/step | 人形平台 |

> ⚠️ 所有运动控制策略的推理延迟均需满足 **<10ms**（对应 100Hz+ 控制频率），这是真实部署的硬约束。GR00T N1 采用双系统架构（慢速 VLM 推理 50ms + 快速策略执行 1ms）来解决这一矛盾。
