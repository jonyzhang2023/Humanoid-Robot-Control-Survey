# AdaptManip: Learning Adaptive Whole-Body Object Lifting and Delivery with Online Recurrent State Estimation

**Authors:** Morgan Byrd, Donghoon Baek, Kartik Garg, Hyunyoung Jung, Daesol Cho, Maks Sorokin, Robert Wright, Sehoon Ha
**Link:** http://arxiv.org/abs/2602.14363v1

## Abstract (from PDF parsing)
...

## Method / Approach (Snippets)
Onbd NoHumRef LocoMan NoFutRef NoTeleOp TWIST [7] ✗ ✗ ✓ ✓ ✓ ResMimic [4] ✗ ✗ ✓ ✓ ✓ VisualMimic [3] ✓ ✗ ✓ ✓ ✗ HDMI [10] ✗ ✗ ✓ ✓ ✓ PhysHSI [11] ✗ ✗ ✓ ✓ ✓ OmniRetarget [5] ✗ ✗ ✓ ✓ ✓ GMT [6] ✓ ✗ ✓ ✗ ✓ BoxLocoManip [12] ✓ ✓ ✓ ✓ ✗ Ours ✓ ✓ ✓ ✓ ✓ grasping after object drops—without relying on motion cap- ture systems or teleoperation. See Table I for a qualitative comparison to existing methods. To realize these capabilities, our framework integrates three key components into a uni- fied system: (1) a reinforcement learning-based locomotion policy for stable bipedal mobility, (2) a residual upper-body manipulation policy for contact-rich object interaction, and (3) a fully onboard object state estimator that provides real-time perception for control. Concretely, the robot operates through three coordinated stages: navigation, lifting, and delivery. During the navigation stage, the humanoid approaches the target object using LiDAR-based robot pose odometry and proprioceptive feedback, enabling fully onboard localization. In the lifting stage, an online object state estimator guides grasping and coordinated whole-body manipulation. In the delivery stage, the robot transports the object to the target location while maintaining balance under changing contact conditions. Overall, AdaptManip achieves higher task success rates than prior baselines by learning robust and adaptive behaviors through reinforcement learning, including recovery actions under failure conditions. This is realized ...

## Conclusion (Snippets)
This paper presents a novel framework for completing whole-body, humanoid loco-manipulation tasks. We introduce AdaptManip, a method which combines multi-modal inputs of LiDAR, vision, and proprioception to maintain a recurrent  8 belief of the box pose and hierarchical RL in order to ef- fectively learn a policy which utilizes the pose for picking up and carrying a box from an initial position to a target location. While we show good results for this box lifting task, interesting future work could include trying more extended tasks, incorporating additional sensor modalities for better object state estimation, or using articulated hands for better manipulation....
