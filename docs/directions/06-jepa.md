---
outline: deep
---

# 方向六：JEPA 与表征空间预测

### 9.1 方向概述与 LeCun 的世界模型愿景

LeCun 2022 年的立场论文 [*A Path Towards Autonomous Machine Intelligence*](https://openreview.net/forum?id=BZ5a1r-kVsf) 提出了以世界模型为核心的自主智能体架构。

**JEPA 的核心主张**：
1. **在抽象表征空间中预测**，而非在像素空间中生成
2. **丢弃不可预测的信息**（噪声、无关细节），聚焦学习世界的**结构**
3. 生成式模型预测输出的每个细节——对高维输入（如视频）来说既浪费又不可行
4. 世界模型是架构的**核心组件**，支持预测、规划和推理

**为什么不用生成式模型？** 世界太复杂，无法在像素空间中预测——太多无关细节。JEPA 在学习到的表征空间中预测，聚焦于重要的内容。这与人类建模世界的方式一致：我们不预测每个光子——我们预测抽象状态和结果。

### 9.2 关键论文深度解析

#### 9.2.1 LeCun 立场论文（2022）— 理论蓝图

提出完整的自主智能体架构蓝图，包含世界模型、配置器（Configurator）、行动者（Actor）、感知模块、记忆模块和评价器（Critic），其中世界模型居于核心位置。

#### 9.2.2 V-JEPA 系列技术演进（2023–2025）

| 版本 | 时间 | 论文 | 核心贡献 |
|------|------|------|---------|
| **I-JEPA** | 2023.01 | [arXiv:2301.08243](https://arxiv.org/abs/2301.08243)（ICCV 2023） | 图像 JEPA：预测遮蔽 patch 的**表征**（非像素），ViT-Huge/14 在 ImageNet 上 <72h 训练 |
| **V-JEPA** | 2024.02 | [arXiv:2404.08471](https://arxiv.org/abs/2404.08471) | 视频 JEPA：遮蔽时空区域并在抽象空间预测，训练效率比生成式高 1.5-6 倍；首个在冻结评估中表现优异的视频模型 |
| **IWM** | 2024.03 | [arXiv:2403.00504](https://arxiv.org/abs/2403.00504) | 图像世界模型：将 JEPA 扩展到预测任意光度变换的效果 |
| **V-JEPA 2** | 2025.06 | [arXiv:2506.09985](https://arxiv.org/abs/2506.09985) | 统一理解、预测和规划的自监督视频模型 |
| **V-JEPA 2-AC** | 2025.06 | 同上 | Action-Conditioned 变体，扩展到具身控制 |

### 9.3 JEPA vs 生成式世界模型

| 维度 | JEPA（LeCun） | 生成式（Sora/Genie） |
|------|-------------|-------------------|
| **预测空间** | 抽象表征空间 | 像素/token 空间 |
| **不可预测细节** | 丢弃（聚焦结构） | 必须生成（浪费） |
| **训练效率** | 高 1.5-6 倍 | 需要海量计算 |
| **多任务复用** | 冻结编码器 + 轻量适配器 | 每个任务需完全微调 |
| **当前强项** | 感知、表征学习、具身控制 | 视觉丰富的交互式世界 |
| **规划集成** | 天然适合（在潜在空间中预测→规划） | 需要额外规划模块 |
| **成熟度** | 快速成熟中（V-JEPA 2 统一三任务） | 更成熟（Sora 2、Genie 3、Cosmos） |

**趋势**：两种范式正在融合——生成式模型日益学习结构化的潜在空间，JEPA 类模型也在扩展到更丰富的预测任务。最终可能需要**混合方法**——抽象世界模型用于规划 + 生成式解码器用于可视化和落地。

### 9.4 前沿论文全景

| 论文 | 时间 | 核心贡献 | 链接 |
|------|------|---------|------|
| [AD-L-JEPA](https://arxiv.org/abs/2501.04969) | 2025.01 | 自动驾驶 LiDAR 数据的 JEPA | [arXiv](https://arxiv.org/abs/2501.04969) |
| [seq-JEPA](https://arxiv.org/abs/2505.03176) | 2025.05 | 自回归预测不变-等变世界模型 | [arXiv](https://arxiv.org/abs/2505.03176) |
| [Causal-JEPA](https://arxiv.org/abs/2602.11389) | 2026.02 | 通过物体级潜在干预学习世界模型 | [arXiv](https://arxiv.org/abs/2602.11389) |
| [VLA-JEPA](https://arxiv.org/abs/2602.10098) | 2026.02 | 潜在世界模型增强 VLA 模型 | [arXiv](https://arxiv.org/abs/2602.10098) |
| Value-guided Action Planning with JEPA | ICLR 2026 Workshop | 基于 JEPA 的价值引导动作规划 | — |

### 9.5 多模态 JEPA 扩展

JEPA 范式已从视觉领域向多模态扩展：

- **Audio-JEPA**（Meta, 2024）将联合嵌入预测架构应用于音频表征学习，在音频事件分类和语音识别上取得与 MAE 可比的性能，但训练效率提高 2 倍
- **MC-JEPA**（Multi-Concept JEPA, 2025）在表征空间中引入多概念分解，实现场景级的组合式世界理解
- **AD-L-JEPA**（§9.4）将 JEPA 扩展到自动驾驶 LiDAR 点云，证明表征空间预测在 3D 感知中同样有效
- **VLA-JEPA**（§9.4）则将 JEPA 与视觉语言动作模型（VLA）结合，显示世界模型增强的 VLA 在多任务具身控制中的优势

这一扩展趋势表明 JEPA 不仅是视觉模型的替代方案，而是有望成为**跨模态统一世界建模的基础范式**。

### 9.6 方向小结

| 特征 | 描述 |
|------|------|
| **优势** | 训练效率高（比生成式节省 1.5-6×）、抗噪声、编码结构化信息、天然适合规划 |
| **局限** | 不可直接可视化（需解码器辅助）、生态成熟度低于生成式方法、多模态融合仍在早期 |
| **趋势** | 在具身 AI 中持续发力（VLA-JEPA、V-JEPA 2-AC）；向多模态扩展（Audio、LiDAR）；与生成式方法走向融合 |
| **代表方法** | I-JEPA、V-JEPA / V-JEPA 2、IWM、Causal-JEPA、VLA-JEPA |
